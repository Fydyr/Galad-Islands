#!/usr/bin/env python3
"""
Script d'entraÃ®nement avancÃ© de l'IA de la base.
Permet d'entraÃ®ner l'IA avec plus de donnÃ©es et de meilleurs paramÃ¨tres.
"""

import sys
import os
import time
from pathlib import Path

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from ia.BaseAi import BaseAi
from constants.gameplay import UNIT_COSTS
import numpy as np
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import joblib


class AdvancedBaseAiTrainer:
    """EntraÃ®neur avancÃ© pour l'IA de la base."""

    def __init__(self, default_team_id=2):
        self.ai = BaseAi(team_id=default_team_id)
        self.gold_reserve = 50
        self.data_path = "src/models/base_ai_training_data.npz"

    def generate_advanced_training_data(self, n_games=200):
        """GÃ©nÃ¨re des donnÃ©es d'entraÃ®nement avancÃ©es avec plus de scÃ©narios."""
        print(f"ğŸ¯ GÃ©nÃ©ration de donnÃ©es avancÃ©es: {n_games} parties...")

        features = []
        labels = []
        action_counts = [0] * 7 # 7 actions: Rien, Eclaireur, Architecte, Maraudeur, LÃ©viathan, Druide, Kamikaze

        for game in range(n_games):
            # Utiliser la simulation amÃ©liorÃ©e de BaseAi
            game_states_actions, game_rewards = self.ai.simulate_game()
            features.extend(game_states_actions)
            labels.extend(game_rewards)
            
            # Compter les actions (approximatif, basÃ© sur les state_action)
            for state_action in game_states_actions:
                action = state_action[-1]  # Dernier Ã©lÃ©ment est l'action
                action_counts[action] += 1

            if (game + 1) % 50 == 0:
                print(f"  ğŸ“Š Parties gÃ©nÃ©rÃ©es: {game + 1}/{n_games}")

        print(f"ğŸ“ˆ DonnÃ©es gÃ©nÃ©rÃ©es: {len(features)} exemples")
        print("ğŸ¯ RÃ©partition des actions dans les donnÃ©es:")
        action_names = ["Rien", "Ã‰claireur", "Architecte", "Maraudeur", "LÃ©viathan", "Druide", "Kamikaze"]
        for i, count in enumerate(action_counts):
            if count > 0:
                percentage = (count / sum(action_counts)) * 100
                print(f"   {action_names[i]}: {count} dÃ©cisions ({percentage:.1f}%)")

        return features, labels

    def _save_training_data(self, states_actions, rewards):
        """Sauvegarde les donnÃ©es d'entraÃ®nement dans un fichier."""
        print(f"ğŸ’¾ Sauvegarde des donnÃ©es d'entraÃ®nement dans {self.data_path}...")
        os.makedirs(os.path.dirname(self.data_path), exist_ok=True)
        np.savez_compressed(self.data_path, states_actions=np.array(states_actions, dtype=object), rewards=np.array(rewards, dtype=object))
        print("âœ… DonnÃ©es sauvegardÃ©es.")

    def _load_training_data(self):
        """Charge les donnÃ©es d'entraÃ®nement depuis un fichier."""
        if not os.path.exists(self.data_path):
            return None, None
        
        print(f"ğŸ’¾ Chargement des donnÃ©es d'entraÃ®nement depuis {self.data_path}...")
        data = np.load(self.data_path, allow_pickle=True)
        print(f"âœ… DonnÃ©es chargÃ©es: {len(data['states_actions'])} exemples.")
        return data['states_actions'].tolist(), data['rewards'].tolist()

    def train_advanced_model(self, n_games=500, use_cached_data=False):
        """EntraÃ®ne un modÃ¨le avancÃ© avec beaucoup de donnÃ©es."""
        start_time = time.time()

        print("=" * 70)
        print("ğŸš€ ENTRAÃNEMENT AVANCÃ‰ DE L'IA DE BASE")
        print("=" * 70)
        print(f"ğŸ¯ Objectif: {n_games} parties simulÃ©es")
        print(f"â° Temps estimÃ©: ~{n_games * 0.02:.1f} secondes")
        print()

        states_actions, rewards = None, None
        if use_cached_data:
            states_actions, rewards = self._load_training_data()

        if states_actions is None or rewards is None:
            # GÃ©nÃ©rer les donnÃ©es d'entraÃ®nement
            states_actions, rewards = self.generate_advanced_training_data(n_games)
            self._save_training_data(states_actions, rewards)

        print()
        print("ğŸ”§ Phase d'entraÃ®nement...")

        X = np.array(states_actions)
        y = np.array(rewards)

        # Split avec stratification pour Ã©quilibrer les classes
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        # ModÃ¨le avec paramÃ¨tres optimisÃ©s pour RL
        model = DecisionTreeRegressor(
            max_depth=6,  # Un peu plus profond pour plus de nuance
            min_samples_split=20,  # Ã‰vite le surapprentissage
            min_samples_leaf=10,
            random_state=42
        )

        model.fit(X_train, y_train)

        # Ã‰valuation
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)

        training_time = time.time() - start_time

        print("âœ… EntraÃ®nement terminÃ©!")
        print()
        print("ğŸ“Š RÃ‰SULTATS DE L'ENTRAÃNEMENT:")
        print("-" * 40)
        print(f"â° Temps d'entraÃ®nement: {training_time:.2f} secondes")
        print(f"ğŸ¯ Erreur quadratique moyenne: {mse:.3f}")
        print(f"   - Profondeur du modÃ¨le: {model.get_depth()}")
        print(f"   - Nombre de feuilles: {model.get_n_leaves()}")
        print(f"   - Ã‰chantillons d'entraÃ®nement: {len(X_train)}")
        print(f"   - Ã‰chantillons de test: {len(X_test)}")
        print()

        return model, mse
        model_path = "src/models/base_ai_advanced_model.pkl"
        os.makedirs("src/models", exist_ok=True)
        joblib.dump(model, model_path)
        print(f"ğŸ’¾ ModÃ¨le sauvegardÃ©: {model_path}")

        print()
        print("=" * 70)
        print("ğŸ‰ ENTRAÃNEMENT AVANCÃ‰ TERMINÃ‰ AVEC SUCCÃˆS!")
        print("=" * 70)

        return model, accuracy


def main():
    """Fonction principale pour l'entraÃ®nement avancÃ©."""
    print("ğŸ¤– EntraÃ®neur d'IA avancÃ© pour Galad Islands")
    print()

    # Demander le nombre de parties
    try:
        n_games = int(input("Nombre de parties Ã  simuler (dÃ©faut: 500): ") or "500")
    except ValueError:
        n_games = 500

    # Demander si on utilise les donnÃ©es en cache
    use_cached_data = False
    data_path = "src/models/base_ai_training_data.npz"
    if os.path.exists(data_path):
        try:
            answer = input(f"Des donnÃ©es d'entraÃ®nement existent dÃ©jÃ  ({data_path}). Les rÃ©utiliser ? [O/n]: ").strip().lower()
            if answer in ('', 'o', 'oui', 'y', 'yes'):
                use_cached_data = True
        except (IOError, EOFError):
            pass

    print(f"ğŸ”¥ Lancement de l'entraÃ®nement avec {n_games} parties...")
    print()

    trainer = AdvancedBaseAiTrainer()
    model, mse = trainer.train_advanced_model(n_games, use_cached_data=use_cached_data)

    print()
    print("ğŸ® Le modÃ¨le avancÃ© est prÃªt Ã  Ãªtre utilisÃ© dans le jeu!")
    print("ğŸ’¡ Pour l'utiliser, modifiez BaseAi.load_or_train_model() pour charger le modÃ¨le avancÃ©.")


if __name__ == "__main__":
    main()