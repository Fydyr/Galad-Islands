#!/usr/bin/env python3
"""
Script d'entraÃ®nement avancÃ© pour l'IA du Kamikaze.
Permet d'entraÃ®ner l'IA avec plus de donnÃ©es et de meilleurs paramÃ¨tres.
"""

import sys
import os
import time
from pathlib import Path

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

import esper
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import joblib

from src.processeurs.UnitAiProcessor import UnitAiProcessor


class AdvancedKamikazeAiTrainer:
    """EntraÃ®neur avancÃ© pour l'IA du Kamikaze."""

    def __init__(self):
        self.processor = None
        self.data_path = "src/models/kamikaze_ai_training_data.npz"

    def _generate_realistic_grid(self):
        """GÃ©nÃ¨re une grille rÃ©aliste comme dans le jeu (Ã®les, nuages) et une liste de mines (positions)."""
        grid = [[0 for _ in range(30)] for _ in range(30)]
        # Placer des Ã®les (valeur 2)
        for _ in range(np.random.randint(6, 10)):
            ix = np.random.randint(3, 27)
            iy = np.random.randint(3, 27)
            grid[ix][iy] = 2
        # Placer des nuages (valeur 3)
        for _ in range(np.random.randint(3, 7)):
            ix = np.random.randint(3, 27)
            iy = np.random.randint(3, 27)
            if grid[ix][iy] == 0:
                grid[ix][iy] = 3
        # GÃ©nÃ©rer des mines (positions alÃ©atoires)
        mines = []
        for _ in range(np.random.randint(2, 5)):
            x = np.random.uniform(200, 1800)
            y = np.random.uniform(200, 1300)
            mines.append({'x': x, 'y': y})
        return grid, mines

    def generate_advanced_training_data(self, n_simulations=1000):
        """GÃ©nÃ¨re des donnÃ©es d'entraÃ®nement avancÃ©es avec plus de simulations et une grille rÃ©aliste (Ã®les, nuages, mines)."""
        print(f"ğŸ¯ GÃ©nÃ©ration de donnÃ©es avancÃ©es: {n_simulations} simulations...")

        esper.clear_database()

        realistic_grid, mines = self._generate_realistic_grid()
        self.processor = UnitAiProcessor(grid=realistic_grid)
        self.processor._mines_for_training = mines

        states, actions, rewards = [], [], []
        try:
            s, a, r = self.processor.generate_advanced_training_data(n_simulations)
            states.extend(s)
            actions.extend(a)
            rewards.extend(r)
        except KeyboardInterrupt:
            print("\nâ¹ï¸ Interruption utilisateur (Ctrl+C) : sauvegarde des donnÃ©es d'entraÃ®nement...")
            self._save_training_data([s + [a] for s, a in zip(states, actions)], rewards)
            print("âœ… DonnÃ©es sauvegardÃ©es aprÃ¨s interruption.")
            raise
        except Exception as e:
            print(f"\nğŸ’¥ Exception inattendue : {e}\nSauvegarde des donnÃ©es d'entraÃ®nement...")
            self._save_training_data([s + [a] for s, a in zip(states, actions)], rewards)
            print("âœ… DonnÃ©es sauvegardÃ©es aprÃ¨s crash.")
            raise
        finally:
            if states:
                print("\nğŸ’¾ Sauvegarde automatique des donnÃ©es d'entraÃ®nement (sortie/crash/interruption)...")
                self._save_training_data([s + [a] for s, a in zip(states, actions)], rewards)
                print("âœ… DonnÃ©es sauvegardÃ©es (finally).")

        print(f"ğŸ“ˆ DonnÃ©es gÃ©nÃ©rÃ©es: {len(states)} exemples")
        print("ğŸ¯ RÃ©partition des rÃ©compenses:")
        positive = sum(1 for r in rewards if r > 0)
        negative = len(rewards) - positive
        print(f"   Positives: {positive} ({positive/len(rewards)*100:.1f}%)")
        print(f"   NÃ©gatives: {negative} ({negative/len(rewards)*100:.1f}%)")

        return [s + [a] for s, a in zip(states, actions)], rewards

    def _save_training_data(self, states_actions, rewards):
        """Sauvegarde les donnÃ©es d'entraÃ®nement dans un fichier."""
        print(f"ğŸ’¾ Sauvegarde des donnÃ©es d'entraÃ®nement dans {self.data_path}...")
        os.makedirs(os.path.dirname(self.data_path), exist_ok=True)
        np.savez_compressed(self.data_path, states_actions=np.array(states_actions, dtype=object), rewards=np.array(rewards, dtype=object))
        print("âœ… DonnÃ©es sauvegardÃ©es.")

    def _load_training_data(self):
        """Charge les donnÃ©es d'entraÃ®nement depuis un fichier."""
        if not os.path.exists(self.data_path):
            return None, None
        
        print(f"ğŸ’¾ Chargement des donnÃ©es d'entraÃ®nement depuis {self.data_path}...")
        data = np.load(self.data_path, allow_pickle=True)
        print(f"âœ… DonnÃ©es chargÃ©es: {len(data['states_actions'])} exemples.")
        return data['states_actions'].tolist(), data['rewards'].tolist()

    def train_advanced_model(self, n_simulations=3000, use_cached_data=False):
        """EntraÃ®ne un modÃ¨le avancÃ© avec beaucoup de simulations."""
        start_time = time.time()

        print("=" * 70)
        print("ğŸš€ ENTRAÃNEMENT AVANCÃ‰ DE L'IA DU KAMIKAZE")
        print("=" * 70)
        print(f"ğŸ¯ Objectif: {n_simulations} simulations")
        print(f"â° Temps estimÃ©: ~{n_simulations * 0.01:.1f} secondes")
        print()

        states_actions, rewards = None, None
        if use_cached_data:
            states_actions, rewards = self._load_training_data()

        if states_actions is None or rewards is None:
            # GÃ©nÃ©rer les donnÃ©es d'entraÃ®nement
            states_actions, rewards = self.generate_advanced_training_data(n_simulations)
            self._save_training_data(states_actions, rewards)

        print()
        print("ğŸ”§ Phase d'entraÃ®nement...")

        X = np.array(states_actions)
        y = np.array(rewards)

        # Split des donnÃ©es
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # Nouveau modÃ¨leÂ : RandomForestRegressor pour plus de robustesse
        from sklearn.ensemble import RandomForestRegressor
        model = RandomForestRegressor(
            n_estimators=40,
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            random_state=42,
            n_jobs=-1
        )

        model.fit(X_train, y_train)

        # Ã‰valuation
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)

        training_time = time.time() - start_time

        print("âœ… EntraÃ®nement terminÃ©!")
        print()
        print("ğŸ“Š RÃ‰SULTATS DE LA FORÃŠT ALÃ‰ATOIRE:")
        print("-" * 40)
        print(f"â° Temps d'entraÃ®nement: {training_time:.2f} secondes")
        print(f"ğŸ¯ Erreur quadratique moyenne finale: {mse:.3f}")
        print(f"   - Nombre d'arbres: {model.n_estimators}")
        print(f"   - Profondeur max: {model.max_depth}")
        print(f"   - Ã‰chantillons d'entraÃ®nement: {len(X_train)}")
        print(f"   - Ã‰chantillons de test: {len(X_test)}")
        print()

        # Sauvegarde du modÃ¨le sous un nom distinct
        rf_model_path = "src/models/kamikaze_ai_rf_model.pkl"
        joblib.dump(model, rf_model_path)
        print(f"ğŸ’¾ ModÃ¨le RandomForest sauvegardÃ©Â : {rf_model_path}")

        return model, mse


def main():
    """Fonction principale pour l'entraÃ®nement avancÃ©."""
    print("ğŸ¤– EntraÃ®neur d'IA avancÃ© pour le Kamikaze - Galad Islands")
    print()

    # Demander le nombre de simulations
    try:
        n_simulations = int(input("Nombre de simulations Ã  effectuer (dÃ©faut: 1000): ") or "1000")
    except ValueError:
        n_simulations = 1000

    # Demander si on utilise les donnÃ©es en cache
    use_cached_data = False
    data_path = "src/models/kamikaze_ai_training_data.npz"
    if os.path.exists(data_path):
        try:
            answer = input(f"Des donnÃ©es d'entraÃ®nement existent dÃ©jÃ  ({data_path}). Les rÃ©utiliser ? [O/n]: ").strip().lower()
            if answer in ('', 'o', 'oui', 'y', 'yes'):
                use_cached_data = True
        except (IOError, EOFError):
            pass

    print(f"ğŸ”¥ Lancement de l'entraÃ®nement avec {n_simulations} simulations...")
    print()

    trainer = AdvancedKamikazeAiTrainer()
    model, mse = trainer.train_advanced_model(n_simulations, use_cached_data=use_cached_data)

    print()
    print("ğŸ® Le modÃ¨le avancÃ© du Kamikaze est prÃªt Ã  Ãªtre utilisÃ© dans le jeu!")
    print("ğŸ’¡ Le modÃ¨le est automatiquement chargÃ© par UnitAiProcessor lors de l'initialisation.")


if __name__ == "__main__":
    main()