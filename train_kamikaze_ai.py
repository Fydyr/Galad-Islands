#!/usr/bin/env python3
"""
Script d'entraÃ®nement avancÃ© pour l'IA du Kamikaze.
Permet d'entraÃ®ner l'IA avec plus de donnÃ©es et de meilleurs paramÃ¨tres.
"""

import sys
import os
import time
from pathlib import Path

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

import esper
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import joblib

from src.processeurs.UnitAiProcessor import UnitAiProcessor


class AdvancedKamikazeAiTrainer:
    """EntraÃ®neur avancÃ© pour l'IA du Kamikaze."""

    def __init__(self):
        self.processor = None
        self.data_path = "src/models/kamikaze_ai_training_data.npz"

    def generate_advanced_training_data(self, n_simulations=1000):
        """GÃ©nÃ¨re des donnÃ©es d'entraÃ®nement avancÃ©es avec plus de simulations."""
        print(f"ðŸŽ¯ GÃ©nÃ©ration de donnÃ©es avancÃ©es: {n_simulations} simulations...")

        # Initialiser esper pour que la simulation fonctionne
        esper.clear_database()

        # CrÃ©er une grille factice pour l'initialisation du processeur
        dummy_grid = [[0 for _ in range(30)] for _ in range(30)]
        dummy_grid[15][15] = 2  # Ajouter une Ã®le au milieu

        # CrÃ©er le processeur pour accÃ©der aux mÃ©thodes de gÃ©nÃ©ration de donnÃ©es
        self.processor = UnitAiProcessor(grid=dummy_grid)

        # Utiliser la mÃ©thode existante pour gÃ©nÃ©rer les donnÃ©es
        states_actions, rewards = self.processor.generate_advanced_training_data(n_simulations)

        print(f"ðŸ“ˆ DonnÃ©es gÃ©nÃ©rÃ©es: {len(states_actions)} exemples")
        print("ðŸŽ¯ RÃ©partition des rÃ©compenses:")
        positive = sum(1 for r in rewards if r > 0)
        negative = sum(1 for r in rewards if r < 0)
        zero = sum(1 for r in rewards if r == 0)
        print(f"   Positives: {positive} ({positive/len(rewards)*100:.1f}%)")
        print(f"   NÃ©gatives: {negative} ({negative/len(rewards)*100:.1f}%)")
        print(f"   Neutres: {zero} ({zero/len(rewards)*100:.1f}%)")

        return states_actions, rewards

    def _save_training_data(self, states_actions, rewards):
        """Sauvegarde les donnÃ©es d'entraÃ®nement dans un fichier."""
        print(f"ðŸ’¾ Sauvegarde des donnÃ©es d'entraÃ®nement dans {self.data_path}...")
        os.makedirs(os.path.dirname(self.data_path), exist_ok=True)
        np.savez_compressed(self.data_path, states_actions=np.array(states_actions, dtype=object), rewards=np.array(rewards, dtype=object))
        print("âœ… DonnÃ©es sauvegardÃ©es.")

    def _load_training_data(self):
        """Charge les donnÃ©es d'entraÃ®nement depuis un fichier."""
        if not os.path.exists(self.data_path):
            return None, None
        
        print(f"ðŸ’¾ Chargement des donnÃ©es d'entraÃ®nement depuis {self.data_path}...")
        data = np.load(self.data_path, allow_pickle=True)
        print(f"âœ… DonnÃ©es chargÃ©es: {len(data['states_actions'])} exemples.")
        return data['states_actions'].tolist(), data['rewards'].tolist()

    def train_advanced_model(self, n_simulations=1000, use_cached_data=False):
        """EntraÃ®ne un modÃ¨le avancÃ© avec beaucoup de simulations."""
        start_time = time.time()

        print("=" * 70)
        print("ðŸš€ ENTRAÃŽNEMENT AVANCÃ‰ DE L'IA DU KAMIKAZE")
        print("=" * 70)
        print(f"ðŸŽ¯ Objectif: {n_simulations} simulations")
        print(f"â° Temps estimÃ©: ~{n_simulations * 0.01:.1f} secondes")
        print()

        states_actions, rewards = None, None
        if use_cached_data:
            states_actions, rewards = self._load_training_data()

        if states_actions is None or rewards is None:
            # GÃ©nÃ©rer les donnÃ©es d'entraÃ®nement
            states_actions, rewards = self.generate_advanced_training_data(n_simulations)
            self._save_training_data(states_actions, rewards)

        print()
        print("ðŸ”§ Phase d'entraÃ®nement...")

        X = np.array(states_actions)
        y = np.array(rewards)

        # Split avec stratification pour Ã©quilibrer les classes
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # ModÃ¨le avec paramÃ¨tres optimisÃ©s pour le Kamikaze
        model = DecisionTreeClassifier(
            max_depth=8,  # Profondeur adaptÃ©e aux dÃ©cisions de mouvement
            min_samples_split=20,  # Ã‰vite le surapprentissage
            min_samples_leaf=10,
            random_state=42
        )

        model.fit(X_train, y_train)

        # Ã‰valuation
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)

        training_time = time.time() - start_time

        print("âœ… EntraÃ®nement terminÃ©!")
        print()
        print("ï¿½ RÃ‰SULTATS DE L'ENTRAÃŽNEMENT:")
        print("-" * 40)
        print(f"â° Temps d'entraÃ®nement: {training_time:.2f} secondes")
        print(f"ðŸŽ¯ Erreur quadratique moyenne finale: {mse:.3f}")
        print(f"   - Profondeur du modÃ¨le: {model.get_depth()}")
        print(f"   - Nombre de feuilles: {model.get_n_leaves()}")
        print(f"   - Ã‰chantillons d'entraÃ®nement: {len(X_train)}")
        print(f"   - Ã‰chantillons de test: {len(X_test)}")
        print()

        return model, mse
        model_path = "models/kamikaze_ai_model.pkl"
        os.makedirs("models", exist_ok=True)
        joblib.dump(model, model_path)
        print(f"ðŸ’¾ ModÃ¨le sauvegardÃ©: {model_path}")

        print()
        print("=" * 70)
        print("ðŸŽ‰ ENTRAÃŽNEMENT AVANCÃ‰ TERMINÃ‰ AVEC SUCCÃˆS!")
        print("=" * 70)

        return model, accuracy


def main():
    """Fonction principale pour l'entraÃ®nement avancÃ©."""
    print("ðŸ¤– EntraÃ®neur d'IA avancÃ© pour le Kamikaze - Galad Islands")
    print()

    # Demander le nombre de simulations
    try:
        n_simulations = int(input("Nombre de simulations Ã  effectuer (dÃ©faut: 1000): ") or "1000")
    except ValueError:
        n_simulations = 1000

    # Demander si on utilise les donnÃ©es en cache
    use_cached_data = False
    data_path = "src/models/kamikaze_ai_training_data.npz"
    if os.path.exists(data_path):
        try:
            answer = input(f"Des donnÃ©es d'entraÃ®nement existent dÃ©jÃ  ({data_path}). Les rÃ©utiliser ? [O/n]: ").strip().lower()
            if answer in ('', 'o', 'oui', 'y', 'yes'):
                use_cached_data = True
        except (IOError, EOFError):
            pass

    print(f"ðŸ”¥ Lancement de l'entraÃ®nement avec {n_simulations} simulations...")
    print()

    trainer = AdvancedKamikazeAiTrainer()
    model, mse = trainer.train_advanced_model(n_simulations, use_cached_data=use_cached_data)

    print()
    print("ðŸŽ® Le modÃ¨le avancÃ© du Kamikaze est prÃªt Ã  Ãªtre utilisÃ© dans le jeu!")
    print("ðŸ’¡ Le modÃ¨le est automatiquement chargÃ© par UnitAiProcessor lors de l'initialisation.")


if __name__ == "__main__":
    main()