#!/usr/bin/env python3
"""
Script d'entraÃ®nement avancÃ© pour l'IA du Kamikaze.
Permet d'entraÃ®ner l'IA avec plus de donnÃ©es et de meilleurs paramÃ¨tres.
"""


import sys
import os
import time
from pathlib import Path

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, str(Path(__file__).parent / "src"))

import esper
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import joblib

from src.components.globals import mapComponent
from src.processeurs.KamikazeAiProcessor import KamikazeAiProcessor
from src.constants.map_tiles import TileType
from src.settings.settings import TILE_SIZE
from sklearn.ensemble import RandomForestRegressor



class AdvancedKamikazeAiTrainer:
    """EntraÃ®neur avancÃ© pour l'IA du Kamikaze."""

    def __init__(self):
        self.processor = None
        self.data_path = "src/models/kamikaze_ai_training_data.npz"

    def _generate_realistic_grid(self):
        """GÃ©nÃ¨re une grille rÃ©aliste en utilisant la vraie logique du jeu (mapComponent.py) et une liste de mines (positions)."""
        grid = mapComponent.creer_grille()
        mapComponent.placer_elements(grid)
        # Extraire les positions des mines Ã  partir de la grille
        mines = []
        for y, row in enumerate(grid):
            for x, val in enumerate(row):
                if val == TileType.MINE:
                    # Position centrale de la tuile
                    mines.append({'x': (x + 0.5) * TILE_SIZE, 'y': (y + 0.5) * TILE_SIZE})
        return grid, mines

    def generate_advanced_training_data(self, n_simulations=1000):
        """GÃ©nÃ¨re des donnÃ©es d'entraÃ®nement avancÃ©es avec plus de simulations et une grille rÃ©aliste (Ã®les, nuages, mines)."""
        print(f"ğŸ¯ GÃ©nÃ©ration de donnÃ©es avancÃ©es: {n_simulations} simulations...")

        esper.clear_database()

        realistic_grid, mines = self._generate_realistic_grid()
        self.processor = KamikazeAiProcessor(grid=realistic_grid, auto_train_model=False)
        # Si besoin, passer les mines via une mÃ©thode ou paramÃ¨tre officiel, sinon ignorer

        states, actions, rewards = [], [], []
        try:
            s, a, r = self.processor.generate_advanced_training_data(n_simulations)
            states.extend(s)
            actions.extend(a)
            rewards.extend(r)
        except KeyboardInterrupt:
            print("\nâ¹ï¸ Interruption utilisateur (Ctrl+C) : sauvegarde des donnÃ©es d'entraÃ®nement...")
            self._save_training_data([s + [a] for s, a in zip(states, actions)], rewards)
            print("âœ… DonnÃ©es sauvegardÃ©es aprÃ¨s interruption.")
            raise
        except Exception as e:
            print(f"\nğŸ’¥ Exception inattendue : {e}\nSauvegarde des donnÃ©es d'entraÃ®nement...")
            self._save_training_data([s + [a] for s, a in zip(states, actions)], rewards)
            print("âœ… DonnÃ©es sauvegardÃ©es aprÃ¨s crash.")
            raise

        # Sauvegarde automatique si tout s'est bien passÃ©
        if states:
            print("\nğŸ’¾ Sauvegarde automatique des donnÃ©es d'entraÃ®nement...")
            self._save_training_data([s + [a] for s, a in zip(states, actions)], rewards)
            print("âœ… DonnÃ©es sauvegardÃ©es.")

        print(f"ğŸ“ˆ DonnÃ©es gÃ©nÃ©rÃ©es: {len(states)} exemples")
        print("ğŸ¯ RÃ©partition des rÃ©compenses:")
        positive = sum(1 for r in rewards if r > 0)
        negative = len(rewards) - positive
        print(f"   Positives: {positive} ({positive/len(rewards)*100:.1f}%)")
        print(f"   NÃ©gatives: {negative} ({negative/len(rewards)*100:.1f}%)")

        return [s + [a] for s, a in zip(states, actions)], rewards

    def _save_training_data(self, states_actions, rewards, append=True):
        """Sauvegarde les donnÃ©es d'entraÃ®nement dans un fichier, en mode append si demandÃ©."""
        print(f"ğŸ’¾ Sauvegarde des donnÃ©es d'entraÃ®nement dans {self.data_path}... (append={append})")
        os.makedirs(os.path.dirname(self.data_path), exist_ok=True)
        if append and os.path.exists(self.data_path):
            # Charger l'existant et concatÃ©ner
            data = np.load(self.data_path, allow_pickle=True)
            old_states = data['states_actions'].tolist()
            old_rewards = data['rewards'].tolist()
            states_actions = old_states + states_actions
            rewards = old_rewards + rewards
        np.savez_compressed(self.data_path, states_actions=np.array(states_actions, dtype=object), rewards=np.array(rewards, dtype=object))
        print("âœ… DonnÃ©es sauvegardÃ©es.")

    def _load_training_data(self):
        """Charge les donnÃ©es d'entraÃ®nement depuis un fichier."""
        if not os.path.exists(self.data_path):
            return None, None
        
        print(f"ğŸ’¾ Chargement des donnÃ©es d'entraÃ®nement depuis {self.data_path}...")
        data = np.load(self.data_path, allow_pickle=True)
        print(f"âœ… DonnÃ©es chargÃ©es: {len(data['states_actions'])} exemples.")
        return data['states_actions'].tolist(), data['rewards'].tolist()

    def train_advanced_model(self, n_simulations=3000, use_cached_data=False, only_train_on_existing_data=False, batch_append=True):
        """EntraÃ®ne un modÃ¨le avancÃ© avec beaucoup de simulations."""
        start_time = time.time()

        print("=" * 70)
        print("ğŸš€ ENTRAÃNEMENT AVANCÃ‰ DE L'IA DU KAMIKAZE")
        print("=" * 70)
        print(f"ğŸ¯ Objectif: {n_simulations} simulations")
        print(f"â° Temps estimÃ©: ~{n_simulations * 0.01:.1f} secondes")
        print()

        states_actions, rewards = None, None
        if use_cached_data or only_train_on_existing_data:
            states_actions, rewards = self._load_training_data()

        if only_train_on_existing_data:
            if not states_actions or not rewards:
                print("âŒ Aucune donnÃ©e existante Ã  utiliser pour l'entraÃ®nement.")
                return None, None
        else:
            # GÃ©nÃ©rer les donnÃ©es d'entraÃ®nement (et append)
            new_states_actions, new_rewards = self.generate_advanced_training_data(n_simulations)
            self._save_training_data(new_states_actions, new_rewards, append=batch_append)
            # Charger toutes les donnÃ©es accumulÃ©es
            states_actions, rewards = self._load_training_data()

        print()
        print("ğŸ”§ Phase d'entraÃ®nement...")

        X = np.array(states_actions)
        y = np.array(rewards)

        # Split des donnÃ©es
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        # Nouveau modÃ¨leÂ : RandomForestRegressor pour plus de robustesse
        from sklearn.ensemble import RandomForestRegressor
        model = RandomForestRegressor(
            n_estimators=40,
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            random_state=42,
            n_jobs=-1
        )

        model.fit(X_train, y_train)

        # Ã‰valuation
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)

        training_time = time.time() - start_time

        print("âœ… EntraÃ®nement terminÃ©!")
        print()
        print("ğŸ“Š RÃ‰SULTATS DE LA FORÃŠT ALÃ‰ATOIRE:")
        print("-" * 40)
        print(f"â° Temps d'entraÃ®nement: {training_time:.2f} secondes")
        print(f"ğŸ¯ Erreur quadratique moyenne finale: {mse:.3f}")
        # Affichage robuste des paramÃ¨tres du modÃ¨le
        params = model.get_params() if hasattr(model, 'get_params') else {}
        if 'n_estimators' in params:
            print(f"   - Nombre d'arbres: {params['n_estimators']}")
        if 'max_depth' in params:
            print(f"   - Profondeur max: {params['max_depth']}")
        print(f"   - Ã‰chantillons d'entraÃ®nement: {len(X_train)}")
        print(f"   - Ã‰chantillons de test: {len(X_test)}")
        print()

        # Sauvegarde du modÃ¨le sous un nom distinct
        rf_model_path = "src/models/kamikaze_ai_rf_model.pkl"
        joblib.dump(model, rf_model_path)
        print(f"ğŸ’¾ ModÃ¨le RandomForest sauvegardÃ©Â : {rf_model_path}")

        return model, mse


def main():
    """Fonction principale pour l'entraÃ®nement avancÃ©."""
    print("ğŸ¤– EntraÃ®neur d'IA avancÃ© pour le Kamikaze - Galad Islands")
    print()

    import argparse
    parser = argparse.ArgumentParser(description="EntraÃ®nement IA Kamikaze par batchs ou complet.")
    parser.add_argument('--batch', type=int, default=0, help="Nombre de simulations Ã  gÃ©nÃ©rer et ajouter (batch). Si 0, pas de gÃ©nÃ©ration.")
    parser.add_argument('--train', action='store_true', help="EntraÃ®ner le modÃ¨le Ã  partir de toutes les donnÃ©es accumulÃ©es.")
    parser.add_argument('--nocache', action='store_true', help="Ne pas utiliser les donnÃ©es en cache (force la gÃ©nÃ©ration d'un nouveau batch).")
    args = parser.parse_args()

    trainer = AdvancedKamikazeAiTrainer()

    if args.batch > 0:
        print(f"ğŸ”¥ GÃ©nÃ©ration d'un batch de {args.batch} simulations et ajout aux donnÃ©es...")
        trainer.generate_advanced_training_data(args.batch)
        print("âœ… Batch ajoutÃ©. Tu peux relancer pour ajouter d'autres batchs.")

    if args.train:
        print("\nï¿½ EntraÃ®nement du modÃ¨le Ã  partir de toutes les donnÃ©es accumulÃ©es...")
        model, mse = trainer.train_advanced_model(n_simulations=0, use_cached_data=True, only_train_on_existing_data=True)
        if model is not None:
            print()
            print("ğŸ® Le modÃ¨le avancÃ© du Kamikaze est prÃªt Ã  Ãªtre utilisÃ© dans le jeu!")
            print("ğŸ’¡ Le modÃ¨le est automatiquement chargÃ© par KamikazeAiProcessor lors de l'initialisation.")
        else:
            print("âŒ EntraÃ®nement impossible : pas de donnÃ©es.")

    if not args.batch and not args.train:
        print("Utilisation :\n  python train_kamikaze_ai.py --batch 5000   # GÃ©nÃ¨re et ajoute 5000 simulations\n  python train_kamikaze_ai.py --train       # EntraÃ®ne le modÃ¨le sur toutes les donnÃ©es accumulÃ©es\n  (tu peux enchaÃ®ner plusieurs batchs avant d'entraÃ®ner)")


if __name__ == "__main__":
    main()