---
i18n:
  en: "AI System"
  fr: "Syst√®me d'IA"
---

# Syst√®me d'Intelligence Artificielle (IA)

## Vue d'ensemble

Le syst√®me d'IA de Galad Islands est con√ßu pour offrir un adversaire cr√©dible et des comportements autonomes pour les unit√©s. Il combine des mod√®les de Machine Learning pour les d√©cisions strat√©giques de haut niveau (comme la `BaseAi`) et des logiques plus simples pour les comportements individuels des unit√©s (comme le `KamikazeAiProcessor`).

## IA de la Base (`BaseAi`)

**Fichier** : `src/ia/BaseAI.py`

L'IA de la base est le cerveau strat√©gique de l'√©quipe adverse. Elle d√©cide quelle unit√© produire en fonction de l'√©tat actuel du jeu.

### Architecture

- **Mod√®le** : `RandomForestRegressor` de Scikit-learn. Ce mod√®le est un ensemble d'arbres de d√©cision qui pr√©dit une "valeur Q" (une estimation de la r√©compense future) pour chaque action possible.
- **Fichier mod√®le** : Le mod√®le entra√Æn√© est sauvegard√© dans `src/models/base_ai_unified_final.pkl`.
- **Logique de d√©cision** : Pour prendre une d√©cision, l'IA √©value toutes les actions possibles (produire chaque type d'unit√©, ou ne rien faire) et choisit celle avec la plus haute valeur Q pr√©dite, tout en v√©rifiant si elle a assez d'or.

### Vecteur d'√©tat (State Vector)

Le mod√®le prend en entr√©e un vecteur d√©crivant l'√©tat du jeu, combin√© √† une action possible. La pr√©diction est la r√©compense attendue pour cet √©tat-action.

Le vecteur d'√©tat-action est compos√© des 9 caract√©ristiques suivantes :

| Index | Caract√©ristique | Description |
|---|---|---|
| 0 | `gold` | Or disponible pour l'IA. |
| 1 | `base_health_ratio` | Sant√© de la base de l'IA (ratio de 0.0 √† 1.0). |
| 2 | `allied_units` | Nombre d'unit√©s alli√©es. |
| 3 | `enemy_units` | Nombre d'unit√©s ennemies connues. |
| 4 | `enemy_base_known` | Si la position de la base ennemie est connue (0 ou 1). |
| 5 | `towers_needed` | Indicateur binaire si des tours de d√©fense sont n√©cessaires. |
| 6 | `enemy_base_health` | Sant√© de la base ennemie (ratio). |
| 7 | `allied_units_health` | Sant√© moyenne des unit√©s alli√©es (ratio). |
| 8 | `action` | L'action envisag√©e (entier de 0 √† 6). |

### Processus d'entra√Ænement

L'entra√Ænement est r√©alis√© par le script `train_unified_base_ai.py`. Il combine plusieurs sources de donn√©es pour cr√©er un mod√®le robuste :

1. **Sc√©narios Strat√©giques (`generate_scenario_examples`)**
    - Des exemples de jeu sont g√©n√©r√©s √† partir de sc√©narios cl√©s d√©finis manuellement (ex: "D√©fense prioritaire", "Exploration n√©cessaire", "Coup de gr√¢ce").
    - Chaque sc√©nario associe un √©tat de jeu √† une action attendue et une r√©compense √©lev√©e. Les actions incorrectes re√ßoivent une p√©nalit√©.
    - Certains sc√©narios comme l'exploration et la d√©fense sont surrepr√©sent√©s pour renforcer ces comportements.

2. **Auto-apprentissage (`simulate_self_play_game`)**
    - Des parties compl√®tes sont simul√©es entre deux instances de l'IA.
    - Chaque d√©cision prise et la r√©compense obtenue sont enregistr√©es comme une exp√©rience.
    - Cela permet √† l'IA de d√©couvrir des strat√©gies √©mergentes dans un contexte de jeu r√©aliste.

3. **Objectif de Victoire (`generate_victory_scenario`)**
    - Similaire √† l'auto-apprentissage, mais avec un bonus de r√©compense tr√®s important pour l'IA qui gagne la partie (en d√©truisant la base adverse).
    - Cela renforce l'objectif final de la victoire et incite l'IA √† prendre des d√©cisions qui y m√®nent.

Toutes ces donn√©es sont ensuite utilis√©es pour entra√Æner le `RandomForestRegressor`.

### D√©monstration

Le script `demo_base_ai.py` permet de tester les d√©cisions de l'IA dans divers sc√©narios et de v√©rifier que son comportement est conforme aux attentes strat√©giques.

```python
# Extrait de demo_base_ai.py
scenarios = [
    {
        "name": "D√©but de partie - Exploration n√©cessaire",
        "gold": 100,
        "enemy_base_known": 0, # <-- Base ennemie inconnue
        "expected": "√âclaireur"
    },
    {
        "name": "D√©fense prioritaire - Base tr√®s endommag√©e",
        "gold": 150,
        "base_health_ratio": 0.5, # <-- Sant√© basse
        "expected": "Maraudeur"
    },
    # ... autres sc√©narios
]
```

### Cr√©ation et Entra√Ænement d'une Nouvelle IA de Base

Pour cr√©er ou affiner une nouvelle version de l'IA de la base, le processus implique principalement la modification du script d'entra√Ænement `train_unified_base_ai.py` et potentiellement de la logique de d√©cision √† base de r√®gles dans `BaseAi.decide_action_for_training`.

**√âtapes cl√©s :**

1. **D√©finir les comportements souhait√©s (le "professeur")**
    - La m√©thode `BaseAi.decide_action_for_training` agit comme un "professeur" pour le mod√®le de Machine Learning. C'est ici que vous d√©finissez les r√®gles de d√©cision id√©ales pour l'IA dans divers √©tats du jeu.
    - Si vous souhaitez que l'IA apprenne de nouveaux comportements ou modifie ses priorit√©s (par exemple, privil√©gier un nouveau type d'unit√© ou une strat√©gie de d√©fense diff√©rente), vous devez d'abord impl√©menter ces r√®gles dans cette m√©thode.
    - Le mod√®le de Machine Learning apprendra ensuite √† imiter et √† g√©n√©raliser ces r√®gles √† travers les simulations.

2. **Ajuster les sc√©narios strat√©giques (`generate_scenario_examples`)**
    - Dans `train_unified_base_ai.py`, la fonction `generate_scenario_examples` cr√©e des exemples de jeu bas√©s sur des situations cl√©s.
    - Si vous introduisez de nouvelles unit√©s ou des m√©caniques de jeu importantes, il est crucial d'ajouter des sc√©narios pertinents ici pour guider l'IA vers les bonnes d√©cisions dans ces contextes.
    - Vous pouvez ajuster le `repeat` et `reward_val` pour surpond√©rer certains comportements jug√©s plus importants.

3. **Ex√©cuter l'entra√Ænement unifi√© (`train_unified_base_ai.py`)**
    - Le script `train_unified_base_ai.py` orchestre l'ensemble du processus d'entra√Ænement :
        - G√©n√©ration d'exemples √† partir de sc√©narios strat√©giques.
        - Simulation de parties compl√®tes en auto-apprentissage (`simulate_self_play_game`).
        - Simulation de parties avec un objectif de victoire renforc√© (`generate_victory_scenario`).
    - Ex√©cutez le script avec les param√®tres souhait√©s (nombre de sc√©narios, de parties de self-play, etc.) :

        ```bash
        python train_unified_base_ai.py --n_scenarios 2000 --n_selfplay 1000 --n_victory 500 --n_iterations 5
        ```

    - Le script sauvegardera le mod√®le entra√Æn√© sous `src/models/base_ai_unified_final.pkl`.

4. **V√©rifier le comportement de l'IA (`demo_base_ai.py`)**
    - Utilisez le script `demo_base_ai.py` pour tester le nouveau mod√®le dans une s√©rie de sc√©narios pr√©d√©finis.
    - Assurez-vous que l'IA prend les d√©cisions attendues et que son comportement est conforme √† vos attentes strat√©giques.
    - Si le comportement n'est pas satisfaisant, retournez √† l'√©tape 1 ou 2 pour affiner les r√®gles et les sc√©narios d'entra√Ænement.

5. **Int√©grer le nouveau mod√®le dans le jeu**
    - Une fois satisfait du mod√®le, assurez-vous que la m√©thode `BaseAi.load_or_train_model()` dans `src/ia/BaseAi.py` est configur√©e pour charger le fichier `base_ai_unified_final.pkl`. C'est le comportement par d√©faut si ce fichier existe.
    - La classe `BaseAi` en jeu ne contient plus la logique d'entra√Ænement, elle se contente de charger et d'utiliser le mod√®le.

Ce processus it√©ratif permet d'affiner progressivement l'intelligence de la base pour qu'elle devienne un adversaire plus sophistiqu√© et r√©actif.

## IA des Unit√©s

> üöß **Section en cours de r√©daction**

En plus de l'IA de la base, certaines unit√©s poss√®dent leur propre logique de comportement autonome, g√©r√©e par des processeurs ECS d√©di√©s.

### IA des Kamikazes (`KamikazeAiProcessor`)

**Fichier** : `src/ia/KamikazeAi.py`

Contrairement √† l'IA de la base, l'IA du Kamikaze n'utilise pas de mod√®le de Machine Learning. Il s'agit d'une **IA proc√©durale hybride** qui combine des algorithmes classiques pour obtenir un comportement de navigation intelligent et r√©actif.

Ce processeur g√®re le comportement des unit√©s Kamikaze :

- **Recherche de cible** : Si la base ennemie n'est pas encore d√©couverte (`KnownBaseProcessor`), le Kamikaze explore des points al√©atoires dans le territoire ennemi. Une fois la base trouv√©e, il identifie en priorit√© les unit√©s ennemies lourdes √† proximit√©. Si aucune n'est trouv√©e, il cible la base ennemie.
- **Navigation √† long terme (Pathfinding A\*)** : Il calcule un chemin optimal vers sa cible en utilisant l'algorithme A*. Pour √©viter que l'unit√© ne "colle" aux obstacles, le pathfinding est ex√©cut√© sur une "carte gonfl√©e" (`inflated_world_map`) o√π les √Æles sont artificiellement √©largies.

    ```python
    # Extrait de KamikazeAiProcessor.py
    
    # Le chemin est calcul√© sur une carte o√π les obstacles sont plus larges
    path = self.astar(self.inflated_world_map, start_grid, goal_grid)
    
    if path:
        # Le chemin est ensuite converti en coordonn√©es mondiales
        world_path = [(gx * TILE_SIZE + TILE_SIZE / 2, gy * TILE_SIZE + TILE_SIZE / 2) for gx, gy in path]
        self._kamikaze_paths[ent] = {'path': world_path, ...}
    ```

- **Navigation √† court terme (√âvitement local)** : C'est le c≈ìur de la r√©activit√© de l'IA. √Ä chaque instant, il d√©tecte les dangers imm√©diats (projectiles, mines) et combine sa direction de chemin avec un "vecteur d'√©vitement" pour contourner ces dangers de mani√®re fluide.

    ```python
    # Extrait de KamikazeAiProcessor.py

    # 1. Vecteur vers la cible du chemin (waypoint)
    desired_direction_vector = np.array([math.cos(math.radians(desired_direction_angle)), ...])

    # 2. Vecteur d'√©vitement (pousse l'unit√© loin des dangers)
    avoidance_vector = np.array([0.0, 0.0])
    for threat_pos in threats:
        # ... calcul du vecteur d'√©vitement pour chaque menace
        avoidance_vector += avoid_vec * weight

    # 3. Combinaison des deux vecteurs
    final_direction_vector = (1.0 - blend_factor) * desired_direction_vector + blend_factor * avoidance_vector
    ```

- **Recalcul dynamique** : Si son chemin est obstru√© par un nouveau danger (comme une mine), il est capable de recalculer enti√®rement un nouvel itin√©raire.

    ```python
    # Extrait de KamikazeAiProcessor.py
    all_dangers = threats + obstacles
    if any(math.hypot(wp[0] - danger.x, wp[1] - danger.y) < 2 * TILE_SIZE for wp in path_to_check for danger in all_dangers):
        # Un danger obstrue le chemin, il faut recalculer
        recalculate_path = True
    ```

- **Action** : Une fois √† port√©e de sa cible finale, l'unit√© s'autod√©truit.
- **Boost Strat√©gique** : L'IA conserve son boost et l'active sp√©cifiquement lorsqu'elle s'approche de la base ennemie pour maximiser ses chances d'atteindre la cible.

### IA des Eclaireurs (`RapidTroopAIProcessor`)

L'IA des √©claireurs (Scouts ennemis) repose sur une machine √† √©tats finis (FSM) et un syst√®me de priorit√©s pour choisir l'action la plus pertinente √† chaque instant. Elle utilise des r√®gles et des scores pour chaque objectif (pas de machine learning).

**Cycle de d√©cision :**

1. Mise √† jour du contexte (sant√©, position, danger)
2. √âvaluation des objectifs (coffre, druide, attaque, base, survie)
3. S√©lection de l'objectif prioritaire
4. Changement d'√©tat si besoin (`Idle`, `GoTo`, `Flee`, `Attack`, etc.)
5. Ex√©cution de l'action (d√©placement, tir, fuite...)

**Objectifs principaux :**

- Collecter les coffres volants (gain d'or pour acheter des alli√©s)
- Survivre le plus longtemps
- Attaquer tactiquement √† distance s√©curis√©e avec tir continu
- Si un Druide est pr√©sent et la sant√© bonne, harc√®lement de base √† distance s√©curis√©e

#### Architecture du syst√®me

Principaux composants :

- `RapidTroopAIProcessor` : boucle principale, gestion des contr√¥leurs, √©v√©nements, overlay debug
- `RapidUnitController` : d√©cisions et ex√©cution pour une unit√©, actualisation contexte, FSM, coordination, tir continu
- `GoalEvaluator` : √©valuation s√©quentielle par priorit√©s, gestion coordination
- Services auxiliaires : `DangerMapService`, `PathfindingService`, `PredictionService`, `CoordinationService`, `AIContextManager`, `IAEventBus`

#### √âvaluation des objectifs (`GoalEvaluator`)

Objectifs par priorit√© :

- `goto_chest` (100) : coffres visibles + non assign√©s
- `follow_druid` (90) : sant√© < 95% + druide pr√©sent
- `attack` (80) : unit√©s ennemies stationnaires
- `follow_die` (70) : ennemi < 60 HP + r√¥le assign√©
- `attack_base` (60) : base ennemie + sant√© > 35%
- `survive` (10) : fallback

Logique s√©quentielle : priorit√© maximale : coffres ‚Üí druide ‚Üí harc√®lement ‚Üí ex√©cution ‚Üí attaque base ‚Üí survie


#### Machine √† √©tats finis (FSM)

√âtats : `Idle`, `GoTo`, `Flee`, `Attack`, `FollowDruid`, `FollowToDie`

Transitions globales et locales selon priorit√© et conditions (danger, sant√©, navigation, etc.)

#### √âtats d√©taill√©s

- **IdleState** : drift vers zone s√ªre, attend transitions, annule navigation si inactive
- **FleeState** : mouvement vers safest_point, hysteresis, cooldown, interdit si sant√© > 50%
- **GoToState** : navigation A* vers target, replan, tol√©rance waypoint
- **AttackState** : anchor system, positions valides autour cible, tir continu
- **FollowToDieState** : poursuite aggressive, ignore danger, tir continu
- **FollowDruid** : approche druide, orbite s√©curis√©e, transition Idle si sant√© r√©tablie

#### Syst√®me de danger

- Sources dynamiques : projectiles, temp√™tes, bandits, unit√©s alli√©es
- Sources statiques : mines, √Æles, bords carte

#### Pathfinding pond√©r√© (A*)

- Co√ªts de tuiles, optimisations (sub-tile factor, blocked margin, recompute distance, waypoint radius)

#### Logique de combat

- Tir continu (`_try_continuous_shoot`) chaque tick, orientation automatique, reset cooldown
- `AttackState` : anchor computation, distance optimale, position al√©atoire, ajustement

#### Coordination inter-unit√©s

- R√¥les exclusifs (coffres, harc√®lement, follow-to-die)
- Services de coordination, event bus, prediction

#### Configuration JSON externe

Exemple :

```json
{
    "danger": {"safe_threshold": 0.45, "flee_threshold": 0.7},
    "weights": {"survive": 4.0, "chest": 3.0, "attack": 1.6}
}
```

#### Seuils critiques

- Sant√©, temps, distances (voir d√©tails dans `Decisions.md`)

#### Fichiers cl√©s et structure

- `src/ia_troupe_rapide/` : `config.py`, `processors/rapid_ai_processor.py`, `services/*`, `states/*`, `fsm/machine.py`, `integration.py`


#### Points d'optimisation actuels

- **Phase 1** : Stabilisation (tir continu, navigation persistante, coordination r√¥les rotatifs)
- **Phase 2** : Tuning (seuils danger, distance anchor, poids objectifs)
- **Phase 3** : Advanced (pr√©diction horizon, micro-positions, load-balance)


### Autres IA (√† venir)

Des logiques d'IA pourraient √™tre ajout√©es pour d'autres unit√©s, par exemple :

- **Druides** : Soigner automatiquement les alli√©s les plus bless√©s √† proximit√©.
- **L√©vithans** : Utiliser des attaques de zone contre des groupes d'ennemis.
- **Maraudeurs** : Prioriser les cibles en fonction de leur menace et de leur valeur strat√©gique.
- **Architectes** : Construire des structures d√©fensives en fonction des menaces d√©tect√©es.

---
